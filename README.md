# ShortsIn - AI-Powered Short Video Generator

<div align="center">

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/Python-3.8%2B-blue)](https://www.python.org/downloads/)
[![Status: Active Development](https://img.shields.io/badge/Status-Active%20Development-brightgreen)](https://github.com/prudvireddyNS/lablabai-hackathon)

Transform your ideas into captivating short videos with the power of AI

</div>

## ğŸ“º Overview

ShortsIn is an innovative AI-powered platform designed to automatically generate engaging short-form videos. By leveraging cutting-edge artificial intelligence and machine learning technologies, ShortsIn transforms raw content, scripts, or concepts into polished, publication-ready short videos optimized for platforms like TikTok, Instagram Reels, YouTube Shorts, and more.

### Key Features

- **ğŸ¬ Intelligent Video Generation**: Automatically create videos from text, scripts, or prompts
- **ğŸ¨ Smart Visual Design**: AI-powered visual composition and scene generation
- **ğŸ”Š Dynamic Audio Processing**: Voice synthesis and music integration
- **âš¡ Fast Processing**: Generate videos in minutes, not hours
- **ğŸ“± Platform Optimization**: Auto-formatted for all major short-video platforms
- **ğŸ­ Style Customization**: Multiple visual themes and creative styles
- **ğŸŒ Multi-language Support**: Generate videos in various languages
- **ğŸ“Š Analytics Integration**: Track video performance and engagement

## ğŸš€ Getting Started

### Prerequisites

- Python 3.8 or higher
- pip or conda for package management
- Git for version control
- API keys for AI services (as configured)

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/prudvireddyNS/lablabai-hackathon.git
   cd lablabai-hackathon
   ```

2. **Create a virtual environment**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Configure environment variables**
   ```bash
   cp .env.example .env
   # Edit .env with your API keys and configuration
   ```

5. **Run the application**
   ```bash
   python main.py
   ```

## ğŸ’» Usage

### Basic Example

```python
from shortsin import VideoGenerator

# Initialize the generator
generator = VideoGenerator(api_key="your_api_key")

# Generate a video from text
video = generator.create_video(
    prompt="A fun tutorial on making the perfect coffee",
    duration=30,  # 30 seconds
    style="energetic",
    language="en"
)

# Export the video
video.export("output/coffee_tutorial.mp4")
```

### Advanced Usage

```python
from shortsin import VideoGenerator, VideoConfig

config = VideoConfig(
    platform="tiktok",
    aspect_ratio="9:16",
    music_genre="upbeat",
    subtitle_style="modern",
    color_palette="vibrant"
)

generator = VideoGenerator(api_key="your_api_key", config=config)

# Generate with custom parameters
video = generator.create_video(
    script="Welcome to our channel...",
    visual_theme="minimalist",
    transitions="smooth",
    effects_intensity="medium"
)
```

## ğŸ“ Project Structure

```
lablabai-hackathon/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ settings.py
â”‚   â”œâ”€â”€ generators/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ video_generator.py
â”‚   â”‚   â”œâ”€â”€ audio_processor.py
â”‚   â”‚   â””â”€â”€ visual_renderer.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ ai_models.py
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ helpers.py
â”‚   â””â”€â”€ api/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ endpoints.py
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_generator.py
â”‚   â””â”€â”€ test_utils.py
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ API.md
â”‚   â”œâ”€â”€ INSTALLATION.md
â”‚   â””â”€â”€ EXAMPLES.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md
```

## ğŸ› ï¸ Technologies Used

- **Python 3.8+**: Core programming language
- **OpenAI API**: Advanced AI model integration
- **FFmpeg**: Video processing and encoding
- **MoviePy**: Video composition and editing
- **Pyttsx3/gTTS**: Text-to-speech synthesis
- **PIL/OpenCV**: Image processing
- **FastAPI**: Web API framework (optional)
- **PyTorch**: Deep learning capabilities

## ğŸ”§ Configuration

Create a `.env` file in the project root:

```env
# API Keys
OPENAI_API_KEY=your_openai_api_key
ELEVENLABS_API_KEY=your_elevenlabs_api_key

# Application Settings
APP_ENV=development
LOG_LEVEL=INFO
VIDEO_OUTPUT_DIR=./output
MAX_VIDEO_DURATION=120
DEFAULT_PLATFORM=tiktok

# Processing Settings
ENABLE_GPU=True
NUM_WORKERS=4
CACHE_ENABLED=True
```

## ğŸ“š API Documentation

For detailed API documentation, see [API.md](docs/API.md)

### Endpoint Example

```
POST /api/v1/generate
Content-Type: application/json

{
  "prompt": "Create a trending video about...",
  "duration": 30,
  "style": "energetic",
  "platform": "tiktok"
}
```

## ğŸ§ª Testing

Run the test suite:

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=src

# Run specific test file
pytest tests/test_generator.py -v
```

## ğŸŒŸ Features in Development

- [ ] Real-time video preview
- [ ] Batch video generation
- [ ] Custom music library integration
- [ ] Advanced subtitle styling
- [ ] Social media auto-posting
- [ ] Analytics dashboard
- [ ] Team collaboration tools
- [ ] Web-based UI

## ğŸ“Š Performance

- Average generation time: 2-5 minutes for 30-second videos
- Supported resolutions: Up to 4K
- Platform support: TikTok, Instagram Reels, YouTube Shorts, Snapchat
- Concurrent video generation: Up to 10 simultaneous videos

## ğŸ¤ Contributing

We welcome contributions! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

Please read [CONTRIBUTING.md](CONTRIBUTING.md) for details on our code of conduct and development process.

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- [LabLab.ai](https://lablab.ai) for the hackathon platform
- OpenAI for GPT models and AI capabilities
- The open-source community for incredible tools and libraries
- All contributors and supporters of this project

## ğŸ“§ Contact & Support

- **Email**: [your-email@example.com]
- **GitHub Issues**: [Report bugs here](https://github.com/prudvireddyNS/lablabai-hackathon/issues)
- **Discussions**: [Join our community](https://github.com/prudvireddyNS/lablabai-hackathon/discussions)

## ğŸ—ºï¸ Roadmap

See the [open issues](https://github.com/prudvireddyNS/lablabai-hackathon/issues) for a list of proposed features and known issues.

### Q1 2026 Goals
- [ ] v1.0 release with core features
- [ ] Web dashboard launch
- [ ] Multi-language expansion

### Q2 2026 Goals
- [ ] Mobile app development
- [ ] Advanced analytics suite
- [ ] Enterprise features

---

<div align="center">

**Made with â¤ï¸ by the ShortsIn Team**

[Star us on GitHub](https://github.com/prudvireddyNS/lablabai-hackathon) â­

</div>
